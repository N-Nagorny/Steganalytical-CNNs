{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images and convolve it before CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.exposure import rescale_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 256, 256\n",
    "cover_path = 'BOSSbase_1.01-256/cover/0/'\n",
    "stego_path = 'BOSSbase_1.01-256/stego/0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(image, kernel):\n",
    "    i_width, i_height = image.shape[0], image.shape[1]\n",
    "    k_width, k_height = kernel.shape[0], kernel.shape[1]\n",
    "    pad = k_width // 2\n",
    "    output = np.zeros((i_width - 2*pad, i_height - 2*pad), dtype=\"float32\")\n",
    "\n",
    "    for y in range(pad, i_height - pad):\n",
    "        for x in range(pad, i_width - pad):\n",
    "            weighted_pixel_sum = 0\n",
    "            roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    "            for ky in range(0, k_height):\n",
    "                for kx in range(0, k_width):\n",
    "                    weighted_pixel_sum += roi[ky, kx] * kernel[ky, kx]\n",
    "            output[y - pad, x - pad] = weighted_pixel_sum\n",
    "\n",
    "    output = rescale_intensity(output, in_range=(0, 255))\n",
    "    output = (output * 255).astype(\"uint8\")\n",
    " \n",
    "    # return the output image\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array((\n",
    "    [-1,  2,  -2,  2, -1],\n",
    "    [ 2, -6,   8, -6,  2],\n",
    "    [-2,  8, -12,  8, -2],\n",
    "    [ 2, -6,   8, -6,  2],\n",
    "    [-1,  2,  -2,  2, -1]), dtype=\"float\")\n",
    "kernel = np.divide(kernel, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_file_data = np.empty([height, width])\n",
    "\n",
    "stego_file_data = np.empty([height, width])\n",
    "\n",
    "for file_number in range(1, 1001):\n",
    "    cover_image = cv2.imread(cover_path + str(file_number) + '.pgm', cv2.IMREAD_GRAYSCALE)\n",
    "    cover_file_data = np.vstack((cover_file_data, cover_image))\n",
    "    \n",
    "    stego_image = cv2.imread(stego_path + str(file_number) + '.pgm', cv2.IMREAD_GRAYSCALE)\n",
    "    stego_file_data = np.vstack((stego_file_data, stego_image))\n",
    "\n",
    "cover_file_data = np.delete(cover_file_data.reshape(1001, height, width), 0,0)\n",
    "\n",
    "stego_file_data = np.delete(stego_file_data.reshape(1001, height, width), 0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = height - 2 * (kernel.shape[0] // 2)\n",
    "width = width - 2 * (kernel.shape[0] // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_convolved_data = np.empty([1000, height, width])\n",
    "for i in range(1000):\n",
    "    cover_convolved_data[i] = convolve(cover_file_data[i], kernel)\n",
    "    \n",
    "stego_convolved_data = np.empty([1000, height, width])\n",
    "for i in range(1000):\n",
    "    stego_convolved_data[i] = convolve(stego_file_data[i], kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zeros for cover; ones for stego\n",
    "cover_train_data = cover_convolved_data.reshape(1000,-1)\n",
    "cover_train_data = np.c_[np.zeros([1000,1]), cover_train_data]\n",
    "\n",
    "stego_train_data = stego_convolved_data.reshape(1000,-1)\n",
    "stego_train_data = np.c_[np.ones([1000,1]), stego_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stego_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_X_train = cover_train_data[:,1:]\n",
    "cover_Y_train = cover_train_data[:,0]\n",
    "\n",
    "stego_X_train = stego_train_data[:,1:]\n",
    "stego_Y_train = stego_train_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((cover_X_train, stego_X_train), axis = 0)\n",
    "Y_train = np.concatenate((cover_Y_train, stego_Y_train), axis = 0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], height, width, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, AveragePooling2D, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "# seed = 3243\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "Y_train = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_activation(x):\n",
    "    sigma = 1\n",
    "    return K.exp(-(x*x)/(sigma*sigma))\n",
    "\n",
    "get_custom_objects().update({'gaussian_activation': Activation(gaussian_activation)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, 5, activation='gaussian_activation', padding='same', input_shape=(height, width, 1)))\n",
    "model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(16, 3, activation='gaussian_activation', padding='same'))\n",
    "model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(16, 3, activation='gaussian_activation', padding='same'))\n",
    "model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(16, 3, activation='gaussian_activation', padding='same'))\n",
    "model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Conv2D(16, 5, activation='gaussian_activation', padding='same'))\n",
    "model.add(AveragePooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', 'categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, Y_train, validation_split=0.1, epochs=100, batch_size=batch_size,\n",
    "                 callbacks=[\n",
    "#                      EarlyStopping(patience=3),\n",
    "                     PlotLossesKeras()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
